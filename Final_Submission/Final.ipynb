{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import shutil\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "'''\n",
    "Change back to tensorflow.keras to turn on lazy loading of imports and to\n",
    "match the exact keras version that tensorflow uses as of tensorflow 2.10\n",
    "'''\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from keras.models import Model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Lambda, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate, BatchNormalization\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.layers import Dropout, GlobalAveragePooling2D, Dense, Flatten, Activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "'''\n",
    "---\n",
    "Configuration params\n",
    "---\n",
    "\n",
    "Changing these after importing doesn't affect function defaults, but do affect\n",
    "functions that use these configurations directly.\n",
    "'''\n",
    "\n",
    "dataset_path = Path(\n",
    "    'BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    ")\n",
    "'''\n",
    "The path where the two class folders (benign, malignant) of images reside.\n",
    "\n",
    "raw strings can be used in-case you use a Windows path with `\\`.\n",
    "\n",
    "If you want any other paths in this script to be cross platform, you *must* use\n",
    "the forward slash `/` to make the paths work on Linux or Mac. But if you are\n",
    "just using a path on only a Windows machine (like this DATASET_PATH) you can\n",
    "use `\\`.\n",
    "\n",
    "Also note you can't end a raw string with a `\\` (and don't need to in this case\n",
    "as we just need the path up to the folder)\n",
    "'''\n",
    "\n",
    "class_list = ['benign', 'malignant']\n",
    "'''\n",
    "List of expected class subfolders in the dataset folder.\n",
    "'''\n",
    "\n",
    "train_split = 0.6\n",
    "'''\n",
    "Set the train split. Train, validation, test split must add up to approximately 1.0.\n",
    "'''\n",
    "\n",
    "validation_split = 0.1\n",
    "'''\n",
    "Set the validation split. Train, validation, test split must add up to approximately 1.0.\n",
    "'''\n",
    "\n",
    "test_split = 1.0 - validation_split - train_split\n",
    "'''\n",
    "Set the test split. Train, validation, test split must add up to approximately 1.0.\n",
    "'''\n",
    "\n",
    "random_seed = 154\n",
    "'''\n",
    "Used for configuring a consistent RANDOM_SEED where we need randomness with\n",
    "reproducable results, like when shuffling the order of images.\n",
    "'''\n",
    "\n",
    "batch_size = 128\n",
    "'''\n",
    "The batch_size for training.\n",
    "'''\n",
    "\n",
    "image_size = (224, 340)\n",
    "'''\n",
    "The image size of all images in the dataset.\n",
    "'''\n",
    "\n",
    "crop_size = (224, 224)\n",
    "'''\n",
    "The size to randomly crop all images to during preprocessing (including train, validation, test).\n",
    "'''\n",
    "\n",
    "model_name = \"group_13_best_model.h5\"\n",
    "'''\n",
    "The name of the file to save the best model to (in .h5 format).\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_train_val_test_split_into_folders(\n",
    "        dataset_path,\n",
    "        *,\n",
    "        class_list=class_list,\n",
    "        split_data_path=None,\n",
    "        move=False,\n",
    "        train_split=train_split,\n",
    "        validation_split=validation_split,\n",
    "        test_split=test_split,\n",
    "        random_seed=random_seed):\n",
    "    \"\"\"\n",
    "    Loops through the `class_list` and splits the data set into train, test,\n",
    "    and validation datasets. The images will be in `split_data_path`/`\n",
    "\n",
    "    Args:\n",
    "        dataset_path (Path, optional): The folder that contains the class folders with pngs in the class folders or any folder below. Defaults to DATASET_PATH.\n",
    "        class_list (list, optional): List of expected class subfolders. Defaults to class_list.\n",
    "        split_data_path (Path, optional): Where to output the split data. Defaults to None (meaning dataset_path/'split_data').\n",
    "        move (bool, optional): Move files from `dataset_path` if True, else copy the files. Defaults to False.\n",
    "        train_split (float, optional): Amount to split into training. Defaults to train_split.\n",
    "        validation_split (float, optional): Amount to split into validation. Defaults to validation_split.\n",
    "        test_split (float, optional): Amount to split into test. Defaults to test_split.\n",
    "        random_seed (int, optional): random seed to use for shuffling. Defaults to random_seed.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: All splits must add up to approximately 1.0, if they don't this is raised.\n",
    "\n",
    "    Returns:\n",
    "        list(str): A list of strings, one each for train, validation, test path.\n",
    "    \"\"\"\n",
    "\n",
    "    TRAIN_FOLDER_NAME = 'training'\n",
    "    VALIDATION_FOLDER_NAME = 'validation'\n",
    "    TEST_FOLDER_NAME = 'test'\n",
    "\n",
    "    if split_data_path is None:\n",
    "        split_data_path = dataset_path / 'split_data'\n",
    "\n",
    "    split_total = train_split + validation_split + test_split\n",
    "    EXPECTED_SPLIT_TOTAL = 1.0\n",
    "    if not math.isclose(split_total, EXPECTED_SPLIT_TOTAL):\n",
    "        raise ValueError(\n",
    "            'train_split + validation_split + test_split ({}) is not approximately = {}'.format(split_total, EXPECTED_SPLIT_TOTAL))\n",
    "\n",
    "    copy_move_str = 'Copying'\n",
    "    if move:\n",
    "        copy_move_str = 'Moving'\n",
    "\n",
    "    development_split = train_split + validation_split\n",
    "\n",
    "    destination_paths = []\n",
    "\n",
    "    allow_move_or_copy = True\n",
    "\n",
    "    if split_data_path.exists():\n",
    "        print(\n",
    "            f\"Not {copy_move_str.lower()} files as {split_data_path} already esists\")\n",
    "        allow_move_or_copy = False\n",
    "\n",
    "    split_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for class_index, class_ in enumerate(class_list):\n",
    "        class_images = glob(\n",
    "            str(dataset_path / class_ / '**/*.png'), recursive=True)\n",
    "\n",
    "        # Shuffles the list in place.\n",
    "        random.Random(random_seed).shuffle(class_images)\n",
    "\n",
    "        development_length = int(development_split * len(class_images))\n",
    "\n",
    "        print(f'Development {class_} set length: {development_length}')\n",
    "        print(\n",
    "            f'Test {class_} set length: {len(class_images) - development_length}')\n",
    "\n",
    "        development_class_image_paths = class_images[:development_length]\n",
    "        test_class_image_paths = class_images[development_length:]\n",
    "\n",
    "        print(\n",
    "            f'Development {class_} image count: {len(development_class_image_paths)}')\n",
    "        print(f'Test {class_} image count: {len(test_class_image_paths)}')\n",
    "\n",
    "        '''\n",
    "        / does float division in python3 and we expect these numbers to be float\n",
    "        anyways.\n",
    "\n",
    "        TRAIN_SPLIT is relative to DEVELOPMENT_SPLIT images because we are working\n",
    "        with an images subset, and the numbers are absolute to the total dataset.\n",
    "        '''\n",
    "        training_length = int(train_split / development_split *\n",
    "                              len(development_class_image_paths))\n",
    "\n",
    "        print(f'Training {class_} set length: {training_length}')\n",
    "        print(\n",
    "            f'Validation {class_} set length: {len(development_class_image_paths) - training_length}')\n",
    "\n",
    "        training_class_image_paths = development_class_image_paths[:training_length]\n",
    "        validation_class_image_paths = development_class_image_paths[training_length:]\n",
    "        print(\n",
    "            f'Training {class_} image count: {len(training_class_image_paths)}')\n",
    "        print(\n",
    "            f'Validation {class_} image count: {len(validation_class_image_paths)}')\n",
    "\n",
    "        split_folder_name_split_image_class_paths_dict = {\n",
    "            TRAIN_FOLDER_NAME: training_class_image_paths,\n",
    "            VALIDATION_FOLDER_NAME: validation_class_image_paths,\n",
    "            TEST_FOLDER_NAME: test_class_image_paths\n",
    "        }\n",
    "\n",
    "        print()\n",
    "\n",
    "        for split_folder_name, split_class_image_paths in split_folder_name_split_image_class_paths_dict.items():\n",
    "            split_path = split_data_path / split_folder_name\n",
    "            destination_path: Path = split_path / class_\n",
    "\n",
    "            '''\n",
    "            Only append destination paths and make the split folders on the\n",
    "            first class_ iteration. We don't want duplicate folders.\n",
    "            '''\n",
    "            if class_index == 0:\n",
    "                destination_paths.append(str(split_path))\n",
    "                split_path.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "            '''\n",
    "            Make the class folder in each split folder\n",
    "            '''\n",
    "            destination_path.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "            if allow_move_or_copy:\n",
    "                print(\n",
    "                    f'{copy_move_str} {split_folder_name} files from {dataset_path} to {destination_path}')\n",
    "                for split_class_image_path in split_class_image_paths:\n",
    "                    if move == True:\n",
    "                        shutil.move(split_class_image_path,\n",
    "                                    str(destination_path))\n",
    "                    else:\n",
    "                        shutil.copy(split_class_image_path,\n",
    "                                    str(destination_path))\n",
    "\n",
    "        '''\n",
    "        If not the last iteration and allow_move_or_copy...\n",
    "        '''\n",
    "        if class_index != len(class_list) and allow_move_or_copy:\n",
    "            print()\n",
    "\n",
    "    return destination_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_val(\n",
    "        training_dataset_path,\n",
    "        validation_dataset_path,\n",
    "        *,\n",
    "        image_size=image_size,\n",
    "        crop_size=crop_size,\n",
    "        batch_size=batch_size):\n",
    "    \"\"\" \n",
    "    This function will take parameters for the datas file path along with the image, crop, and batch size. It will then perform the training\n",
    "    set's cropping and data augmentation and return the dataset once it is transformed.\n",
    "    \"\"\"\n",
    "\n",
    "    crop_layer = tf.keras.layers.CenterCrop(*crop_size)\n",
    "    augmentation_layer = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.RandomFlip(),\n",
    "            tf.keras.layers.RandomRotation((-0.2, 0.2), seed=random_seed),\n",
    "            tf.keras.layers.RandomContrast(0.1, seed=random_seed),\n",
    "            tf.keras.layers.RandomHeight(0.2, seed=random_seed),\n",
    "            tf.keras.layers.RandomWidth(0.2, seed=random_seed),\n",
    "            tf.keras.layers.Resizing(224, 340, crop_to_aspect_ratio=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        training_dataset_path,\n",
    "        shuffle=True,\n",
    "        label_mode='categorical',\n",
    "        seed=random_seed,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size)\n",
    "\n",
    "    validation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        validation_dataset_path,\n",
    "        shuffle=False,\n",
    "        label_mode='categorical',\n",
    "        seed=random_seed,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size)\n",
    "\n",
    "    train_ds = train_ds.map(\n",
    "        lambda image, label: (\n",
    "            augmentation_layer(image, training=True),\n",
    "            label),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    train_ds = train_ds.map(\n",
    "        lambda image, label: (\n",
    "            crop_layer(image, training=True),\n",
    "            label),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    validation_ds = validation_ds.map(\n",
    "        lambda image, label: (\n",
    "            crop_layer(image, training=True),\n",
    "            label),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return train_ds.prefetch(buffer_size=AUTOTUNE), validation_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(\n",
    "        path,\n",
    "        *,\n",
    "        image_size=image_size,\n",
    "        crop_size=crop_size,\n",
    "        batch_size=batch_size):\n",
    "\n",
    "    crop_layer = tf.keras.layers.CenterCrop(*crop_size)\n",
    "\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        path,\n",
    "        label_mode='categorical',\n",
    "        seed=random_seed,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size)\n",
    "\n",
    "    test_ds = test_ds.map(\n",
    "        lambda image, label: (\n",
    "            crop_layer(image, training=True),\n",
    "            label),\n",
    "        num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    return test_ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESNET\n",
    "def resnet50_builder():# Defining the model\n",
    "    base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "        weights='imagenet',  \n",
    "        input_shape=(224,224,3),\n",
    "        include_top=False) \n",
    "    base_model.trainable = False\n",
    "\n",
    "    x1 = base_model(base_model.input, training = False)\n",
    "    x2 = tf.keras.layers.Flatten()(x1)\n",
    "\n",
    "\n",
    "    out = tf.keras.layers.Dense(2, activation = 'softmax')(x2)\n",
    "    model = tf.keras.Model(inputs = base_model.input, outputs =out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19\n",
    "\n",
    "def vgginnet_builder():\n",
    "    base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    layer_name = 'block4_pool'\n",
    "    feature_ex_model = Model(inputs=base_model.input, \n",
    "                             outputs=base_model.get_layer(layer_name).output, \n",
    "                             name='vgg16_features')\n",
    "    feature_ex_model.trainable = False\n",
    "\n",
    "    p1_layer = Lambda(vgg_preprocess, name='VGG_Preprocess')\n",
    "    image_input = Input((224, 224, 3), name='Image_Input')\n",
    "    p1_tensor = p1_layer(image_input)\n",
    "\n",
    "    out =feature_ex_model(p1_tensor)\n",
    "    feature_ex_model = Model(inputs=image_input, outputs=out)\n",
    "\n",
    "    def naive_inception_module(layer_in, f1, f2, f3):\n",
    "        # 1x1 conv\n",
    "        conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "        # 3x3 conv\n",
    "        conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
    "        # 5x5 conv\n",
    "        conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
    "        # 3x3 max pooling\n",
    "        pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "        # concatenate filters, assumes filters/channels last\n",
    "        layer_out = Concatenate()([conv1, conv3, conv5, pool])\n",
    "        return layer_out\n",
    "\n",
    "    out = naive_inception_module(feature_ex_model.output, 64, 128, 32)\n",
    "    num_classes = 2\n",
    "\n",
    "    bn1 = BatchNormalization(name='BN')(out)\n",
    "    f = Flatten()(bn1)\n",
    "    dropout = Dropout(0.4, name='Dropout')(f)\n",
    "    desne = Dense(num_classes, activation='softmax', name='Predictions')(dropout)\n",
    "\n",
    "    model = Model(inputs=feature_ex_model.input, outputs=desne)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnetnaive_builder():\n",
    "    base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "        weights='imagenet',  \n",
    "        input_shape=(224,224,3),\n",
    "        include_top=False) \n",
    "    \n",
    "\n",
    "    layer_name = 'conv5_block3_out'\n",
    "    feature_ex_model = Model(inputs=base_model.input, \n",
    "                             outputs=base_model.get_layer(layer_name).output, \n",
    "                             name='resnet50_features')\n",
    "    feature_ex_model.trainable = False\n",
    "\n",
    "    p1_layer = Lambda(resnet_preprocess, name='Resnet_Preprocess')\n",
    "    image_input = Input((224, 224, 3), name='Image_Input')\n",
    "    p1_tensor = p1_layer(image_input)\n",
    "\n",
    "    out =feature_ex_model(p1_tensor)\n",
    "    feature_ex_model = Model(inputs=image_input, outputs=out)\n",
    "\n",
    "    def naive_inception_module(layer_in, f1, f2, f3):\n",
    "        # 1x1 conv\n",
    "        conv1 = Conv2D(f1, (1,1), padding='same', activation='relu')(layer_in)\n",
    "        # 3x3 conv\n",
    "        conv3 = Conv2D(f2, (3,3), padding='same', activation='relu')(layer_in)\n",
    "        # 5x5 conv\n",
    "        conv5 = Conv2D(f3, (5,5), padding='same', activation='relu')(layer_in)\n",
    "        # 3x3 max pooling\n",
    "        pool = MaxPooling2D((3,3), strides=(1,1), padding='same')(layer_in)\n",
    "        # concatenate filters, assumes filters/channels last\n",
    "        layer_out = Concatenate()([conv1, conv3, conv5, pool])\n",
    "        return layer_out\n",
    "\n",
    "    out = naive_inception_module(feature_ex_model.output, 64, 128, 32)\n",
    "    num_classes = 2\n",
    "\n",
    "    bn1 = BatchNormalization(name='BN')(out)\n",
    "    f = Flatten()(bn1)\n",
    "    dropout = Dropout(0.4, name='Dropout')(f)\n",
    "    desne = Dense(num_classes, activation='softmax', name='Predictions')(dropout)\n",
    "\n",
    "    model = Model(inputs=feature_ex_model.input, outputs=desne)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model: Model, train_ds, val_ds, epochs=5, learning_rate=1e-4):\n",
    "\n",
    "    #\n",
    "    # Define your callbacks (save best model, early stopping, learning rate scheduler)\n",
    "    #\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20)\n",
    "\n",
    "    monitor = tf.keras.callbacks.ModelCheckpoint(\n",
    "        model_name,\n",
    "        monitor='val_loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='min')\n",
    "\n",
    "    # Learning rate schedule\n",
    "    # Reduce learning rate every 4 epochs.\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch % 4 == 0 and epoch != 0:\n",
    "            lr = lr/2\n",
    "        return lr\n",
    "\n",
    "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "        scheduler,\n",
    "        verbose=0)\n",
    "\n",
    "    # Show model summary before training.\n",
    "    print(model.summary())\n",
    "\n",
    "    #\n",
    "    # Configure and train the model\n",
    "    #\n",
    "\n",
    "    # Define optimizer, loss function, and metrics.\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        callbacks=[early_stop, monitor, lr_schedule],\n",
    "        validation_data=(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: Model, test_ds: tf.data.Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        test_ds: Expects test_ds to be preprocessed for pre-trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    model.load_weights(model_name)\n",
    "    metrics = model.evaluate(test_ds)\n",
    "\n",
    "    Ypred = model.predict(test_ds).argmax(axis=1)\n",
    "    label_batch_list = []\n",
    "    for _, label_batch in test_ds:\n",
    "        label_batch_list.append(label_batch)\n",
    "    Y_test_t = tf.concat(label_batch_list, axis=0)\n",
    "    Y_test = Y_test_t.numpy()\n",
    "\n",
    "    wrong_indexes = np.where(Ypred != Y_test)[0]\n",
    "\n",
    "    return metrics, wrong_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\n",
    "    r'C:\\Users\\feagm\\Desktop\\ENEL_645\\Project\\archive\\BreaKHis_v1\\BreaKHis_v1\\histology_slides\\breast'\n",
    ")\n",
    "training_dataset_path,validation_dataset_path, test_dataset_path = stratified_train_val_test_split_into_folders(dataset_path)\n",
    "\n",
    "\n",
    "train_ds, val_ds = preprocess_train_val(training_dataset_path,validation_dataset_path, batch_size=32)\n",
    "test_ds = preprocess_test(test_dataset_path, batch_size=32)\n",
    "model = resnetnaive_builder()\n",
    "train_validate(model, train_ds, val_ds, epochs=30)\n",
    "\n",
    "model = tf.keras.models.load_model(model_name)\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
